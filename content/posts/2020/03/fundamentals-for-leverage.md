---
title: "Leveraging fundamentals"
date: 2020-03-03T21:48:14+02:00
draft: true
---

In my previous [post](/posts/02/the-right-details), I ranted a bit about the state of programming tools based on my struggles working with infrastructure in large-scale systems.
I found the landscape of infrastructure tooling seem to be born from a solution approach that I feel might not be an effective response to complexity (and probably more a result of cultural momentum).
Progress made by incrementalism.
I believe this largely encourages a similarly inadequate design approach in our daily work, when combined with work pressure from problematic methodologies and their practice.
We can do better!

## Lessons from Scientific Research

Last year, I had the immense privilege of attending the International Conference on Accelerator and Large Experimental Physics Control Systems (ICALEPCS 2019).
It was hosted by the Brookhaven National Laboratory, one of the juggernauts of science facilities, boasting no less than 7 Nobel Science Prizes to their name.
Battling jet lag and sleep deprivation, I was struck by a point from one of keynote presentations by associate director Jim Misewich. 
He was presenting an overview of some of the major breakthrough scientific accomplishments that the facility helped with, particularly in imaging technology that allowed scientists to study behaviours of nanomaterials, to imaging individual molecules themselves _during_ reactions.
A particular case stood out to me, 

"Percy Zahl and Y. Zhang, Energy Fuels "


> The building blocks of software development - languages, libraries, and platforms - change significantly every few years. The equivalent in the physical world would be that customers usually add new floors and change the floor-plan once half the building is built and occupied, while the fundamental properties of concrete change every other year.

-- Martin Fowler, [Is High Quality Software Worth The Cost?](https://martinfowler.com/articles/is-quality-worth-cost.html)

